{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mNea5iY7fzvL"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming\n",
        "#### Stemming is used to extract the base form of words by removing the affixes from them.\n",
        "#### Stemming is the process of removing the last few characters of a given word, to obtain a shorter form, even if that form doesn’t have any meaning."
      ],
      "metadata": {
        "id": "o1c8kAinhAy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Porter Stemmer"
      ],
      "metadata": {
        "id": "Kj870j0Aj2oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Porter stemmer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "p_stemmer =  PorterStemmer()"
      ],
      "metadata": {
        "id": "higdBTy5g6is"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['run', 'running', 'ran', 'runner','runs', 'easily', 'fairly']"
      ],
      "metadata": {
        "id": "QLULZ-a7hqPt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + '---------->' + p_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGq8Bx0eh4Kk",
        "outputId": "2e472e80-cadf-4a65-d2bf-7c88ffd7966d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run---------->run\n",
            "running---------->run\n",
            "ran---------->ran\n",
            "runner---------->runner\n",
            "runs---------->run\n",
            "easily---------->easili\n",
            "fairly---------->fairli\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Snowball Stemmer\n",
        "\n",
        "##### Snowball stemmer is little more accurate and efficient than porter stemmer."
      ],
      "metadata": {
        "id": "_VzGP12ljx48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Snowball Stemmer\n",
        "\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "s_stemmer = SnowballStemmer(language='english')"
      ],
      "metadata": {
        "id": "_Kx1dXu_ioSN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + \"------------>\" + s_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-T41XcwjrR6",
        "outputId": "a899672b-c22a-497b-b37e-9e0f9d4d0970"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run------------>run\n",
            "running------------>run\n",
            "ran------------>ran\n",
            "runner------------>runner\n",
            "runs------------>run\n",
            "easily------------>easili\n",
            "fairly------------>fair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# More generous example"
      ],
      "metadata": {
        "id": "fJ_zhZAdlb-o"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Words2 = ['generous', 'generation', 'generates', 'generously']"
      ],
      "metadata": {
        "id": "fAU0QfRtlgxH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from nltk.stem.porter import PorterStemmer\n",
        "#from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "#p_stemmer = PorterStemmer()\n",
        "#s_stemmer = SnowballStemmer(language='english')"
      ],
      "metadata": {
        "id": "NpA-u-m7lgnL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + \"------------>\" + p_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNDBZy5omMes",
        "outputId": "bc08e42c-ffcf-4295-da37-7d161941e18a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run------------>run\n",
            "running------------>run\n",
            "ran------------>ran\n",
            "runner------------>runner\n",
            "runs------------>run\n",
            "easily------------>easili\n",
            "fairly------------>fairli\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + \"-------------------->\" + s_stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbIzMQ1xm7F3",
        "outputId": "c71e7e50-50ee-400c-ffef-de1326eefa64"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run-------------------->run\n",
            "running-------------------->run\n",
            "ran-------------------->ran\n",
            "runner-------------------->runner\n",
            "runs-------------------->run\n",
            "easily-------------------->easili\n",
            "fairly-------------------->fair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatization\n",
        "#### The purpose of lemmatization is same as that of stemming but overcomes the drawbacks of stemming. In stemming, for some words, it may not give may not give meaningful representation such as “Histori”. Here, lemmatization comes into picture as it gives meaningful word.\n"
      ],
      "metadata": {
        "id": "5dvHQezUkicO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "c8dPRqTM7nvY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "UPHGtCpy7r6c"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc6 = nlp(u\"In stemming, for some words, it may not give may not give meaningful representation such as “Histori”. Here, lemmatization comes into picture as it gives meaningful word\")\n"
      ],
      "metadata": {
        "id": "DzAQldFakQni"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc6:\n",
        "  print(f\"{token.text:15}, {token.lemma:22}, {token.lemma_:15}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-Pp7yOU7kok",
        "outputId": "8ad4f5cd-c3e1-4a75-c5d2-3350aca9528f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In             ,    3002984154512732771, in             \n",
            "stemming       ,    8827646899549411103, stem           \n",
            ",              ,    2593208677638477497, ,              \n",
            "for            ,   16037325823156266367, for            \n",
            "some           ,    7000492816108906599, some           \n",
            "words          ,   11916616154811659322, word           \n",
            ",              ,    2593208677638477497, ,              \n",
            "it             ,   10239237003504588839, it             \n",
            "may            ,   14378475389916013800, may            \n",
            "not            ,     447765159362469301, not            \n",
            "give           ,   11640825575873464194, give           \n",
            "may            ,   14378475389916013800, may            \n",
            "not            ,     447765159362469301, not            \n",
            "give           ,   11640825575873464194, give           \n",
            "meaningful     ,    3425937930778810352, meaningful     \n",
            "representation ,    7234704111175374980, representation \n",
            "such           ,   13040105543478938413, such           \n",
            "as             ,    7437575085468336610, as             \n",
            "“              ,   15884554869126768810, \"              \n",
            "Histori        ,    7930025682130217643, Histori        \n",
            "”              ,   15884554869126768810, \"              \n",
            ".              ,   12646065887601541794, .              \n",
            "Here           ,     411390626470654571, here           \n",
            ",              ,    2593208677638477497, ,              \n",
            "lemmatization  ,     438229042533536439, lemmatization  \n",
            "comes          ,    5307304325359566725, come           \n",
            "into           ,    3278561384161438710, into           \n",
            "picture        ,    9284188139451966413, picture        \n",
            "as             ,    7437575085468336610, as             \n",
            "it             ,   10239237003504588839, it             \n",
            "gives          ,   11640825575873464194, give           \n",
            "meaningful     ,    3425937930778810352, meaningful     \n",
            "word           ,   11916616154811659322, word           \n"
          ]
        }
      ]
    }
  ]
}